# 13.核心组件安装之 metrics-server
从 Kubernetes 1.8 开始，Kubernetes 通过 Metrics API 获取资源使用指标，例如容器 CPU 和内存使用情况。这些度量指标可以由用户直接访问，例如通过使用kubectl top 命令，或者使用集群中的控制器，例如， Horizontal Pod Autoscaler。

Metrics API: 通过 Metrics API，您可以获得 node 或 pod 当前的资源使用情况（但是不存储）。

大致是说它符合 kubernetes 的监控架构设计，受 heapster 项目启发，并且比 heapster 优势在于：
  + 访问不需要 apiserver 的代理机制，提供认证和授权等；
  + 很多集群内组件依赖它（HPA,scheduler,kubectl top），因此它应该在集群中默认运行；
  + 部分 kubernetes 集群的安装工具已经默认集成了 Metrics Server 的安装，以下概述下它的安装： 
#### 创建metrics-server证书签名请求
```
cat > metrics-server-csr.json << EOF
{
  "CN": "aggregator",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "4Paradigm"
    }
  ]
}
EOF
```
#### 生成证书
```
cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \
  -ca-key=/etc/kubernetes/ssl/ca-key.pem  \
  -config=./ca-config.json  \
  -profile=kubernetes metrics-server-csr.json | cfssljson -bare metrics-server

ls metrics-server*.pem
```
将 metrics-server*.pem 分发各 master 主机的 /etc/kubernetes/ssl 目录下;
#### 修改api-server相关启动参数
```
  --requestheader-client-ca-file=/etc/kubernetes/ssl/ca.pem \
  --requestheader-allowed-names=aggregator \
  --requestheader-extra-headers-prefix=X-Remote-Extra- \
  --requestheader-group-headers=X-Remote-Group \
  --requestheader-username-headers=X-Remote-User \
  --proxy-client-cert-file=/etc/kubernetes/ssl/metrics-server.pem \
  --proxy-client-key-file=/etc/kubernetes/ssl/metrics-server-key.pem \
  --enable-aggregator-routing=true \
```
#### 修改kube-controllr-manager配置文件
```
--horizontal-pod-autoscaler-use-rest-clients=true
```
用于配置 HPA 控制器使用 REST 客户端获取 metrics 数据;
#### 重启服务
```
systemctl daemon-reload
systemctl restart kube-apiserver
systemctl restart kube-controller-manager
```
#### 部署 metrics-server
下载所需文件：
```
git clone https://github.com/kubernetes-incubator/metrics-server.git
cd ./metrics-server/deploy/1.8+
```
修改 metrics-server-deployment 文件：
```
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: metrics-server
  namespace: kube-system
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: metrics-server
  namespace: kube-system
  labels:
    k8s-app: metrics-server
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  template:
    metadata:
      name: metrics-server
      labels:
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        image: hexun/metrics-server-amd64:v0.3.0
        imagePullPolicy: Always
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
        command:
        - /metrics-server
        - --kubelet-insecure-tls
```
**提示：** 在 metrics-server 0.3.0 中已经取消了 "--source=''" 的支持，因此需要修改成如上内容。因为我的 kubelet 没有使用 https,因此这里需要使用"--kubelet-insecure-tls"、"--kubelet-preferred-address-types=InternalIP" 选项来支持非 https 访问 kubelet 的方式;
#### 创建 metrics-server
```
kubectl apply -f .
```
#### 查看运行情况及验证
```
$ kubectl get pods -n kube-system |grep metrics-server
metrics-server-589cc698c4-fbw5t            1/1       Running   0          46m
$ kubectl get svc -n kube-system|grep metrics-server
metrics-server         ClusterIP   10.254.229.233   <none>        443/TCP         46m
$ kubectl get apiservice|grep metrics
v1beta1.metrics.k8s.io                  2018-09-29T09:31:00Z
$ kubectl top nodes
NAME                             CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%
k8sm01.ops.yws.bj2.yongche.com   1148m        28%       3915Mi          49%
k8sm02.ops.yws.bj2.yongche.com   749m         18%       2895Mi          36%
k8sm03.ops.yws.bj2.yongche.com   1012m        25%       5111Mi          64%
k8sn01.ops.yws.bj2.yongche.com   63m          1%        1524Mi          19%
k8sn02.ops.yws.bj2.yongche.com   39m          0%        1829Mi          23%
k8sn03.ops.yws.bj2.yongche.com   42m          1%        1842Mi          23%
$ kubectl top pods --all-namespaces
NAMESPACE     NAME                                       CPU(cores)   MEMORY(bytes)
kube-system   calico-kube-controllers-858fdb898b-l4b5m   1m           14Mi
kube-system   calico-node-5qmkn                          11m          56Mi
kube-system   calico-node-8jk7g                          11m          53Mi
kube-system   calico-node-h8wlh                          11m          55Mi
kube-system   calico-node-kwzdw                          12m          55Mi
kube-system   calico-node-pbfzz                          11m          55Mi
kube-system   calico-node-qwvpq                          12m          55Mi
kube-system   coredns-55f86bf584-45rb8                   2m           16Mi
kube-system   coredns-55f86bf584-4mnnf                   2m           17Mi
kube-system   heapster-v1.5.3-59c474d675-8mj5l           2m           36Mi
kube-system   kubernetes-dashboard-58d7567f97-68k6l      1m           19Mi
kube-system   metrics-server-589cc698c4-fbw5t            4m           18Mi
kube-system   tiller-deploy-995d4bd4b-5drfw              1m           10Mi
```
#### 查看 metrcs-server 输出的 metrics
直接使用kubectl命令
```
$ kubectl get --raw "/apis/metrics.k8s.io/v1beta1" | jq .
{
  "kind": "APIResourceList",
  "apiVersion": "v1",
  "groupVersion": "metrics.k8s.io/v1beta1",
  "resources": [
    {
      "name": "nodes",
      "singularName": "",
      "namespaced": false,
      "kind": "NodeMetrics",
      "verbs": [
        "get",
        "list"
      ]
    },
    {
      "name": "pods",
      "singularName": "",
      "namespaced": true,
      "kind": "PodMetrics",
      "verbs": [
        "get",
        "list"
      ]
    }
  ]
}
$ kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes" | jq .
{
  "kind": "NodeMetricsList",
  "apiVersion": "metrics.k8s.io/v1beta1",
  "metadata": {
    "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes"
  },
  "items": [
    {
      "metadata": {
        "name": "k8sm01.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sm01.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:29:57Z",
      "window": "30s",
      "usage": {
        "cpu": "1121807816n",
        "memory": "4013416Ki"
      }
    },
    {
      "metadata": {
        "name": "k8sm02.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sm02.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:30:04Z",
      "window": "30s",
      "usage": {
        "cpu": "771670129n",
        "memory": "2963936Ki"
      }
    },
    {
      "metadata": {
        "name": "k8sm03.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sm03.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:30:01Z",
      "window": "30s",
      "usage": {
        "cpu": "848860444n",
        "memory": "5238272Ki"
      }
    },
    {
      "metadata": {
        "name": "k8sn01.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sn01.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:29:59Z",
      "window": "30s",
      "usage": {
        "cpu": "62579472n",
        "memory": "1585592Ki"
      }
    },
    {
      "metadata": {
        "name": "k8sn02.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sn02.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:30:02Z",
      "window": "30s",
      "usage": {
        "cpu": "46367096n",
        "memory": "1874564Ki"
      }
    },
    {
      "metadata": {
        "name": "k8sn03.ops.yws.bj2.yongche.com",
        "selfLink": "/apis/metrics.k8s.io/v1beta1/nodes/k8sn03.ops.yws.bj2.yongche.com",
        "creationTimestamp": "2018-09-29T10:30:05Z"
      },
      "timestamp": "2018-09-29T10:29:55Z",
      "window": "30s",
      "usage": {
        "cpu": "44424793n",
        "memory": "1888004Ki"
      }
    }
  ]
}
```
#### 补充说明
目前 dashboard 插件如果想在界面上显示资源使用率，它还依赖于 heapster；另外。测试发现 k8s 1.8 版本的 kubectl top 也依赖 heapster，因此建议补充安装heapster，无需安装 influxdb 和 grafana。
